{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "from tqdm import tqdm\n",
    "\n",
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_dir = os.getenv('HOME')+'/Desktop/Quest07/data'\n",
    "data_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/data'\n",
    "# model_dir = os.getenv('HOME')+'/Desktop/Quest07/models'\n",
    "model_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/models'\n",
    "\n",
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_8000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "# 특수 token 7개를 제외한 나머지 token 출력\n",
    "vocab_list = []\n",
    "for id in range(7, len(vocab)):\n",
    "    if not vocab.is_unknown(id):\n",
    "        vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "print(len(vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# [CLS], tokens a, [SEP], tokens b, [SEP] 형태의 token 생성\n",
    "string_a = \"추적추적 비가 내리는 날이었어 그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\"\n",
    "string_b = \"손바닥 위엔 기쁨의 눈물이 흘러 컬컬한 목에 모주 한잔을 적셔 몇 달 포 전부터 콜록거리는 아내 생각에 그토록 먹고 싶다던\"\n",
    "tokens_org = [\"[CLS]\"] + vocab.encode_as_pieces(string_a) + [\"[SEP]\"] + vocab.encode_as_pieces(string_b) + [\"[SEP]\"]\n",
    "print(tokens_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    마스크 생성\n",
    "    :param tokens: tokens\n",
    "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
    "    :param vocab_list: vocab list (random token 용)\n",
    "    :return tokens: mask된 tokens\n",
    "    :return mask_idx: mask된 token의 index\n",
    "    :return mask_label: mask된 token의 원래 값\n",
    "    \"\"\"\n",
    "    # 단어 단위로 mask 하기 위해서 index 분할 (띄어쓰기)\n",
    "    cand_idx = []  # word 단위의 index array\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):  # u\"\\u2581\"는 단어의 시작을 의미하는 값\n",
    "            cand_idx[-1].append(i)\n",
    "        else:\n",
    "            cand_idx.append([i])\n",
    "\n",
    "    # random mask를 위해서 순서를 섞음 (shuffle)\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    # mask_lms 정렬 후 mask_idx, mask_label 추출 (sorted 사용)\n",
    "    tokens = copy.deepcopy(tokens)\n",
    "\n",
    "    mask_lms = []  # mask 된 값\n",
    "    for index_set in cand_idx:\n",
    "        if len(mask_lms) >= mask_cnt:  # 현재 mask된 개수가 15%를 넘으면 중지\n",
    "            break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "            continue\n",
    "        dice = random.random()  # 0과 1 사이의 확률 값\n",
    "\n",
    "        for index in index_set:\n",
    "            masked_token = None\n",
    "            if dice < 0.8:  # 80% replace with [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9: # 10% keep original\n",
    "                masked_token = tokens[index]\n",
    "            else:  # 10% random word\n",
    "                masked_token = random.choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "\n",
    "    # 순서 정렬 및 mask_idx, mask_label 생성\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_org\n",
      "['[CLS]', '▁추', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '▁둘', '째', '번', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n",
      "\n",
      "tokens\n",
      "['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '▁첫', '▁번', '에', '▁삼', '십', '▁전', '[MASK]', '[MASK]', '[MASK]', '▁오', '십', '▁전', '▁오', '랜', '만에', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '묽', '▁《', '▁2011', '[SEP]', '▁손', '바', '닥', '▁위', '엔', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '▁컬', '컬', '한', '▁목', '에', '▁모', '주', '[MASK]', '[MASK]', '[MASK]', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전', '부터', '▁콜', '록', '거', '리는', '[MASK]', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '[SEP]'] \n",
      "\n",
      "mask_idx   : [1, 2, 3, 4, 29, 30, 31, 48, 49, 50, 71, 72, 73, 85]\n",
      "mask_label : ['▁추', '적', '추', '적', '▁둘', '째', '번', '▁서', '푼', '에', '▁한', '잔', '을', '▁아내']\n"
     ]
    }
   ],
   "source": [
    "mask_cnt = int((len(tokens_org) - 3) * 0.15)\n",
    "\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)\n",
    "\n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens, \"\\n\")\n",
    "\n",
    "print(\"mask_idx   :\", mask_idx)\n",
    "print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Sentence Prediction pair 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
    "    :param tokens_a: tokens A\n",
    "    :param tokens_b: tokens B\n",
    "    :param max_seq: 두 tokens 길이의 최대 값\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    \"\"\"\n",
    "    # for CLS], [SEP], [SEP]\n",
    "    max_seq = n_seq - 3\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])  # line 단위로 추가\n",
    "        current_length += len(doc[i])  # current_chunk의 token 수\n",
    "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "            # print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "            # token a\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1, len(current_chunk))\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            # token b\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "            if random.random() < 0.5:  # 50% 확률로 swap\n",
    "                is_next = 0    # False\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1   # True\n",
    "            # max_seq 보다 큰 경우 길이 조절\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "\n",
    "            # print(\"is_next:\", is_next)\n",
    "            # print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "            # print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "            #######################################\n",
    "\n",
    "            # tokens & segment 생성\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "            # print(\"tokens:\", len(tokens), tokens)\n",
    "            # print(\"segment:\", len(segment), segment)\n",
    "            \n",
    "            # mask\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
    "            # print(\"masked tokens:\", len(tokens), tokens)\n",
    "            # print(\"masked index:\", len(mask_idx), mask_idx)\n",
    "            # print(\"masked label:\", len(mask_label), mask_label)\n",
    "\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,\n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "            #######################################\n",
    "            # print()\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\"추적추적 비가 내리는 날이었어\n",
    "그날은 왠지 손님이 많아\n",
    "첫 번에 삼십 전 둘째 번 오십 전\n",
    "오랜만에 받아보는 십 전짜리 백통화 서푼에\n",
    "손바닥 위엔 기쁨의 눈물이 흘러\n",
    "컬컬한 목에 모주 한잔을 적셔\n",
    "몇 달 포 전부터 콜록거리는 아내\n",
    "생각에 그토록 먹고 싶다던\n",
    "설렁탕 한 그릇을 이제는 살 수 있어\n",
    "집으로 돌아가는 길 난 문득 떠올라\n",
    "아내의 목소리가 거칠어만 가는 희박한 숨소리가\n",
    "오늘은 왠지 나가지 말라던 내 옆에 있어 달라던\n",
    "그리도 나가고 싶으면 일찍이라도 들어와 달라던\n",
    "아내의 간절한 목소리가 들려와\n",
    "나를 원망하듯 비는 점점 거세져\n",
    "싸늘히 식어가는 아내가 떠올라 걱정은 더해져\n",
    "난 몰라 오늘은 운수 좋은 날\n",
    "난 맨날 이렇게 살 수 있으면 얼마나 좋을까\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [vocab.encode_as_pieces(line) for line in string.split(\"\\n\")]\n",
    "\n",
    "# 최대 길이\n",
    "n_test_seq = 64\n",
    "# 최소 길이\n",
    "min_seq = 8\n",
    "# [CLS], tokens_a, [SEB], tokens_b, [SEP]\n",
    "max_seq = n_test_seq - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', '적', '추', '적', '▁비', '가', '▁내', '리는', '▁날', '이었', '어', '▁그', '날', '은', '▁', '왠', '지', '▁손', '님', '이', '▁많', '아', '[MASK]', '▁번', '에', '▁삼', '십', '[MASK]', '▁둘', '째', '[MASK]', '▁오', '십', '▁전', '[MASK]', '[MASK]', '[MASK]', '▁받아', '보', '는', '▁십', '▁전', '짜', '리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손', '바', '닥', '솜', '벡', '▁기', '쁨', '의', '▁눈', '물이', '▁흘', '러', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [22, 27, 30, 34, 35, 36, 40, 54, 55], 'mask_label': ['▁첫', '▁전', '▁번', '▁오', '랜', '만에', '▁십', '▁위', '엔']}\n",
      "{'tokens': ['[CLS]', '▁집', '으로', '▁돌아', '가는', '盆', '[MASK]', '[MASK]', '[MASK]', '▁떠', '올', '라', '▁아내', '의', '▁목', '소', '리가', '▁거', '칠', '어', '만', '▁가는', '▁희', '박', '한', '▁숨', '소', '리가', '[SEP]', '▁컬', '컬', '한', '핸', '도와', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '[MASK]', '▁전', '부터', '▁콜', '록', '거', '리는', '▁아내', '▁생각', '에', '▁그', '토', '록', '▁먹', '고', '▁싶', '다', '던', '▁설', '렁', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [5, 6, 7, 8, 32, 33, 41, 43, 50], 'mask_label': ['▁길', '▁난', '▁문', '득', '▁목', '에', '▁몇', '▁포', '▁아내']}\n",
      "{'tokens': ['[CLS]', '▁나', '를', '▁원', '망', '하', '듯', '▁비', '는', '▁점', '점', '[MASK]', '[MASK]', '[MASK]', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내', '가', '▁떠', '올', '라', '▁', '걱', '정은', '▁더', '해', '져', '[SEP]', '▁오늘', '은', '[MASK]', '[MASK]', '[MASK]', '▁나', '가지', '▁말', '라', '던', '▁내', '▁옆', '에', '[MASK]', '▁달', '라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일', '찍', '이라', '도', '▁들어', '와', '[MASK]', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [11, 12, 13, 34, 35, 36, 45, 61, 62], 'mask_label': ['▁거', '세', '져', '▁', '왠', '지', '▁있어', '▁달', '라']}\n",
      "{'tokens': ['[CLS]', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁군', '▁있', '으면', '[MASK]', '[MASK]', '▁좋', '을', '까', '[SEP]', '▁난', '▁몰', '라', '▁오늘', '은', '▁운', '수', '▁좋은', '▁날', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [6, 9, 10], 'mask_label': ['▁수', '▁얼마', '나']}\n"
     ]
    }
   ],
   "source": [
    "instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "\n",
    "# 최종 데이터셋 결과 확인\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "\n",
    "    # 특수문자 7개를 제외한 vocab_list 생성\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):        # unknown 단어 제거\n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "    # line count 확인\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\":  # 빈 줄을 만나면 새로운 문단 처리\n",
    "                    if 0 < len(doc):\n",
    "                        save_pretrain_instances(out_f, doc)\n",
    "                        doc = []\n",
    "                else:  # 토큰화 후 문서에 저장\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "\n",
    "            # 마지막 남은 문서 처리\n",
    "            if 0 < len(doc):\n",
    "                save_pretrain_instances(out_f, doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3957761/3957761 [06:12<00:00, 10612.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# corpus_file = os.getenv('HOME')+'/Desktop/Quest07/data/kowiki.txt'\n",
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "# pretrain_json_path = os.getenv('HOME')+'/Desktop/Quest07/data/bert_pre_train.json'\n",
    "pretrain_json_path = os.getenv('HOME')+'/aiffel/bert_pretrain/data/bert_pre_train.json'\n",
    "\n",
    "\n",
    "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918189\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        total += 1\n",
    "        \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 0,\n",
       " 0,\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seq = 128\n",
    "# [CLS], tokens_a, [SEP], tokens_b, [SEP]\n",
    "max_seq = n_seq - 3\n",
    "\n",
    "# np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "\n",
    "enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    학습에 필요한 데이터를 로드\n",
    "    :param vocab: vocab\n",
    "    :param filename: 전처리된 json 파일\n",
    "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
    "    :param count: 데이터 수 제한 (None이면 전체)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # 데이터 수 제한\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int32)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int32)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int32, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128000/128000 [00:22<00:00, 5707.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load early stop 128000 128000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=128000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([   5,   18, 3686,    6,    6,    4, 3324, 1042,  103, 3610, 3686,\n",
       "         3718,  207, 3714,   37, 3418,  416,    6,    6,    6,  131, 3662,\n",
       "            7, 3629,  203,  241, 3602, 1114, 3724,  788,  243,   49, 3632,\n",
       "          796,  663,    6,    6,    6,    6,    6, 3008, 3625, 3616,   16,\n",
       "         3599,   18, 3686,  207, 3714, 3602, 1755, 3630, 3646,  630, 3714,\n",
       "            6,    6,  429, 3740, 3628, 3626, 1369,   10, 1605, 3599, 1755,\n",
       "         3630,   41, 3644,  830, 3624, 1135,   52, 3599,   13,   81,   87,\n",
       "         1501, 2247,   25, 3779, 3873, 3667, 3631, 3813, 3873, 4196, 3636,\n",
       "         3779, 3601,  249, 3725, 1232,    6,    6,    6,  479, 3652, 3625,\n",
       "          243, 2780,   14, 1509,  168, 3877,  414,  165, 1697, 4290, 3873,\n",
       "         3703, 3683,    6,   21, 5007,  399, 1927, 3607,  813,   17, 3599,\n",
       "          307,  587,  931,  103, 4313, 4290,    4], dtype=int32),\n",
       " memmap([   5,   13,   81, 3604,   15, 3784,   68, 3238, 3602,    6,  316,\n",
       "            6,    6,  305, 3620, 1395,  149, 3607,   19,  805, 3596, 4904,\n",
       "         3750, 3603, 4065,  115, 3617, 3756, 3596, 4639, 1364, 3627,  991,\n",
       "         3616, 3600,    6,    6,    6,    6, 2972,  173, 1345, 3604,  848,\n",
       "         3784, 3833,    8, 3637, 2263,   12, 3614, 3746,  836, 3596, 4904,\n",
       "         3750, 3603, 4065,  115, 3600, 2972,  173,  351, 3599,    4,  848,\n",
       "         3784, 3833,    8, 3637, 3676,    6,    6,    6,   58, 3676,  416,\n",
       "         2316, 3619, 3625, 3617, 3744, 4335,   12, 3625, 3616,  175, 3662,\n",
       "            7, 3629, 6849,  578, 3652, 3625, 3617, 4148, 3665,  143, 3625,\n",
       "         3616,  131, 3662,  342, 3629, 3616, 3602,  176,    6,    6, 1115,\n",
       "         3665, 1381, 4148, 3451, 1633,  375,  671, 1644, 3608,  547, 3423,\n",
       "          765,  815, 3604,  752, 3608, 3604,    4], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 1,\n",
       " 0,\n",
       " memmap([   0,    0,    0,  207, 3714,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,  810, 3666, 3625,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0, 1647, 3682, 3682, 3625,  203,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,  630, 3714,\n",
       "         3565, 3835,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,   33,   52, 3599,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,  593,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32),\n",
       " memmap([   0,   13,    0,    0,    0,    0,    0,    0,    0,   13,    0,\n",
       "         1425,  173,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    7, 3614, 3746,    9,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,   12, 3614, 3746,  836,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,  848, 3784, 1931,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,  203,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,  334,  829,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 처음과 마지막 확인\n",
    "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: position embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, self.n_head * self.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer class 정의\n",
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 256,\n",
       " 'n_vocab': 8007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss 계산\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    # 정확도 계산\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param train_steps: 학습 step 총 합\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: 최대 learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate 계산\n",
    "        :param step_num: 현재 step number\n",
    "        :retrun: 계산된 learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute lr \n",
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule(float(step_num)).numpy())\n",
    "\n",
    "# draw\n",
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BERT)                     ((None, 256), (None, 4485632     enc_tokens[0][0]                 \n",
      "                                                                 segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlm (Softmax)                   (None, None, 8007)   0           bert[0][1]                       \n",
      "==================================================================================================\n",
      "Total params: 4,551,936\n",
      "Trainable params: 4,551,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 20000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 268s 124ms/step - loss: 19.6080 - nsp_loss: 0.6500 - mlm_loss: 18.9580 - nsp_acc: 0.5916 - mlm_lm_acc: 0.1082\n",
      "\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.10824, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 253s 127ms/step - loss: 17.5279 - nsp_loss: 0.6215 - mlm_loss: 16.9064 - nsp_acc: 0.6156 - mlm_lm_acc: 0.1299\n",
      "\n",
      "Epoch 00002: mlm_lm_acc improved from 0.10824 to 0.12988, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 15.7275 - nsp_loss: 0.6149 - mlm_loss: 15.1126 - nsp_acc: 0.6253 - mlm_lm_acc: 0.1535\n",
      "\n",
      "Epoch 00003: mlm_lm_acc improved from 0.12988 to 0.15354, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 14.1912 - nsp_loss: 0.6111 - mlm_loss: 13.5801 - nsp_acc: 0.6296 - mlm_lm_acc: 0.1881\n",
      "\n",
      "Epoch 00004: mlm_lm_acc improved from 0.15354 to 0.18807, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 13.4894 - nsp_loss: 0.6077 - mlm_loss: 12.8817 - nsp_acc: 0.6350 - mlm_lm_acc: 0.2084\n",
      "\n",
      "Epoch 00005: mlm_lm_acc improved from 0.18807 to 0.20845, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 13.0652 - nsp_loss: 0.6039 - mlm_loss: 12.4613 - nsp_acc: 0.6408 - mlm_lm_acc: 0.2205\n",
      "\n",
      "Epoch 00006: mlm_lm_acc improved from 0.20845 to 0.22054, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 12.7756 - nsp_loss: 0.5995 - mlm_loss: 12.1761 - nsp_acc: 0.6522 - mlm_lm_acc: 0.2295\n",
      "\n",
      "Epoch 00007: mlm_lm_acc improved from 0.22054 to 0.22952, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 255s 127ms/step - loss: 12.5793 - nsp_loss: 0.5953 - mlm_loss: 11.9840 - nsp_acc: 0.6588 - mlm_lm_acc: 0.2354\n",
      "\n",
      "Epoch 00008: mlm_lm_acc improved from 0.22952 to 0.23542, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 12.4583 - nsp_loss: 0.5917 - mlm_loss: 11.8666 - nsp_acc: 0.6675 - mlm_lm_acc: 0.2392\n",
      "\n",
      "Epoch 00009: mlm_lm_acc improved from 0.23542 to 0.23924, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 12.4007 - nsp_loss: 0.5887 - mlm_loss: 11.8120 - nsp_acc: 0.6727 - mlm_lm_acc: 0.2410\n",
      "\n",
      "Epoch 00010: mlm_lm_acc improved from 0.23924 to 0.24097, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n"
     ]
    }
   ],
   "source": [
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", \n",
    "                                                  monitor=\"mlm_lm_acc\", \n",
    "                                                  verbose=1, \n",
    "                                                  save_best_only=True, \n",
    "                                                  mode=\"max\", \n",
    "                                                  save_freq=\"epoch\", \n",
    "                                                  save_weights_only=True)\n",
    "\n",
    "history = pre_train_model.fit(pre_train_inputs,  # 입력 데이터 (토큰 + 세그먼트 정보)\n",
    "                            pre_train_labels,  # NSP 및 MLM 라벨\n",
    "                            epochs=epochs,  # 에포크 수\n",
    "                            batch_size=batch_size,  # 배치 크기\n",
    "                            callbacks=[save_weights]  # 콜백 함수 (가중치 저장)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 기록에서 loss, accuracy 데이터 추출\n",
    "train_loss = history.history[\"loss\"]\n",
    "train_nsp_acc = history.history[\"nsp_acc\"]\n",
    "train_mlm_acc = history.history[\"mlm_lm_acc\"]\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# 손실(Loss) 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, label=\"Train Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# 정확도(Accuracy) 시각화\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_nsp_acc, label=\"Train NSP Accuracy\", marker=\"o\")\n",
    "plt.plot(epochs, train_mlm_acc, label=\"Train MLM Accuracy\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BERT 모델 학습을 위한 input data 조작을 구현해볼 수 있었다. \n",
    "- 노드 학습에서 BERT를 공부할 때와 다르게 PooledOutput등을 통해 next sentence prediction과 masked language modelling task를 위한 output이 어떻게 계산되는지를 이해하게 되었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
