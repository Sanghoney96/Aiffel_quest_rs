{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, re\n",
    "import random\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU 활성화됨: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# GPU가 사용 가능한 경우, 기본 디바이스를 GPU로 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')  # 첫 번째 GPU만 사용\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)  # 필요할 때만 GPU 메모리 사용\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"✅ GPU 활성화됨:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = os.getenv('HOME')+'/Desktop/Quest05/data'\n",
    "data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
    "\n",
    "# 데이터 정제 및 토큰화\n",
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: \n",
    "        kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: \n",
    "        eng = f.read().splitlines()\n",
    "    assert len(kor) == len(eng)\n",
    "\n",
    "    unique_pairs = set(zip(kor, eng))\n",
    "    cleaned_corpus = list(unique_pairs)\n",
    "\n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 소문자로 변환\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # 알파벳, 문장부호, 한글만 남기고 모두 제거\n",
    "    sentence = re.sub(r\"[^a-zA-Zㄱ-ㅎ가-힣.,!?]\", \" \", sentence)\n",
    "    \n",
    "    # 문장부호 양옆에 공백 추가\n",
    "    sentence = re.sub(r\"([.,!?])\", r\" \\1 \", sentence)\n",
    "    \n",
    "    # 연속된 공백을 하나의 공백으로 변환\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ko_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: ko_tokenizer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 4\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <PAD>\n",
      "  user_defined_symbols: <BOS>\n",
      "  user_defined_symbols: <EOS>\n",
      "  user_defined_symbols: <UNK>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ko_corpus.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78967 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <PAD>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <BOS>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <EOS>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <UNK>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5053325\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1185\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78967 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 159141 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78967\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 195707\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 195707 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=83230 obj=12.5937 num_tokens=378610 num_tokens/piece=4.54896\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=70412 obj=11.4417 num_tokens=379924 num_tokens/piece=5.39573\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=52804 obj=11.4469 num_tokens=396862 num_tokens/piece=7.51576\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=52786 obj=11.4136 num_tokens=397193 num_tokens/piece=7.52459\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=39589 obj=11.5539 num_tokens=420668 num_tokens/piece=10.6259\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=39588 obj=11.5173 num_tokens=420682 num_tokens/piece=10.6265\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=29691 obj=11.7109 num_tokens=447000 num_tokens/piece=15.0551\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=29691 obj=11.6693 num_tokens=447004 num_tokens/piece=15.0552\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22268 obj=11.9067 num_tokens=473397 num_tokens/piece=21.2591\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22268 obj=11.861 num_tokens=473392 num_tokens/piece=21.2588\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22000 obj=11.8794 num_tokens=474461 num_tokens/piece=21.5664\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22000 obj=11.8768 num_tokens=474459 num_tokens/piece=21.5663\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: ko_tokenizer.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: ko_tokenizer.vocab\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: en_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: en_tokenizer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 4\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <PAD>\n",
      "  user_defined_symbols: <BOS>\n",
      "  user_defined_symbols: <EOS>\n",
      "  user_defined_symbols: <UNK>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: en_corpus.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78956 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <PAD>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <BOS>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <EOS>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <UNK>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=10661485\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9909% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=29\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999909\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78956 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 82992 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78956\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 44562\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 44562 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=34535 obj=9.8622 num_tokens=83351 num_tokens/piece=2.41352\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25851 obj=8.0062 num_tokens=83809 num_tokens/piece=3.242\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=21977 obj=7.92346 num_tokens=84668 num_tokens/piece=3.85257\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21848 obj=7.90467 num_tokens=84910 num_tokens/piece=3.8864\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en_tokenizer.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en_tokenizer.vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentencepiece를 활용하여 학습한 tokenizer를 생성합니다.\n",
    "def generate_tokenizer(corpus,\n",
    "                        vocab_size,\n",
    "                        lang=\"ko\",\n",
    "                        pad_id=0,\n",
    "                        bos_id=1,\n",
    "                        eos_id=2,\n",
    "                        unk_id=3):\n",
    "    \n",
    "    # 임시 파일에 말뭉치를 저장\n",
    "    corpus_file = f\"{lang}_corpus.txt\"\n",
    "    model_prefix = f\"{lang}_tokenizer\"\n",
    "\n",
    "    with open(corpus_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for sentence in corpus:\n",
    "            f.write(sentence + \"\\n\")\n",
    "\n",
    "    # SentencePiece 모델 학습\n",
    "    spm.SentencePieceTrainer.Train(input=corpus_file,\n",
    "                                   model_prefix=model_prefix,\n",
    "                                   vocab_size=vocab_size,\n",
    "                                   pad_id=pad_id,\n",
    "                                   bos_id=bos_id,\n",
    "                                   eos_id=eos_id,\n",
    "                                   unk_id=unk_id,\n",
    "                                   user_defined_symbols=[\"<PAD>\", \"<BOS>\", \"<EOS>\", \"<UNK>\"],\n",
    "                                   model_type=\"unigram\",\n",
    "                                   num_threads=4)\n",
    "\n",
    "    # 학습된 모델 로드\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.Load(f\"{model_prefix}.model\")\n",
    "\n",
    "    return tokenizer\n",
    "    \n",
    "\n",
    "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
    "\n",
    "eng_corpus = []\n",
    "kor_corpus = []\n",
    "\n",
    "for pair in cleaned_corpus:\n",
    "    k, e = pair[0], pair[1]\n",
    "\n",
    "    kor_corpus.append(preprocess_sentence(k))\n",
    "    eng_corpus.append(preprocess_sentence(e))\n",
    "\n",
    "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")\n",
    "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")\n",
    "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78968\n"
     ]
    }
   ],
   "source": [
    "print(len(eng_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78968/78968 [00:06<00:00, 13036.87it/s]\n"
     ]
    }
   ],
   "source": [
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "assert len(kor_corpus) == len(eng_corpus)\n",
    "\n",
    "# 토큰의 길이가 50 이하인 문장만 남깁니다. \n",
    "for idx in tqdm(range(len(kor_corpus))):\n",
    "    tokenized_kor = ko_tokenizer.EncodeAsIds(kor_corpus[idx])\n",
    "    tokenized_eng = en_tokenizer.EncodeAsIds(eng_corpus[idx])\n",
    "    \n",
    "    if len(tokenized_kor) <= 50 and len(tokenized_eng) <= 50:\n",
    "        src_corpus.append(tokenized_kor)\n",
    "        tgt_corpus.append(tokenized_eng)\n",
    "\n",
    "# 패딩처리를 완료하여 학습용 데이터를 완성합니다. \n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72143\n",
      "72143\n"
     ]
    }
   ],
   "source": [
    "print(len(src_corpus))\n",
    "print(len(tgt_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    \n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model) # Linear Layer\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        \"\"\"\n",
    "        Embedding을 Head의 수로 분할하는 함수\n",
    "\n",
    "        x: [ batch x length x emb ]\n",
    "        return: [ batch x heads x length x self.depth ]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        x = tf.reshape(x, [batch_size, -1, self.num_heads, self.depth])\n",
    "        split_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "\n",
    "        \"\"\"\n",
    "        Scaled QK 값 구하기\n",
    "        \"\"\"\n",
    "        scaled_qk = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(d_k)\n",
    "        \n",
    "        if mask is not None: \n",
    "            scaled_qk += (mask * -1e9) \n",
    "\n",
    "        \"\"\"\n",
    "        1. Attention Weights 값 구하기 -> attentions\n",
    "        2. Attention 값을 V에 곱하기 -> out\n",
    "        \"\"\" \n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        \"\"\"\n",
    "        분할된 Embedding을 하나로 결합하는 함수\n",
    "\n",
    "        x: [batch x heads x length x self.depth]\n",
    "        return: [batch x length x emb]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "    \n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        \"\"\"\n",
    "        아래 순서에 따라 소스를 작성하세요.\n",
    "\n",
    "        Step 1: Linear_in(Q, K, V) -> WQ, WK, WV\n",
    "        Step 2: Split Heads(WQ, WK, WV) -> WQ_split, WK_split, WV_split\n",
    "        Step 3: Scaled Dot Product Attention(WQ_split, WK_split, WV_split)\n",
    "                 -> out, attention_weights\n",
    "        Step 4: Combine Heads(out) -> out\n",
    "        Step 5: Linear_out(out) -> out\n",
    "        \"\"\"\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "            \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "    \t\t\t\t        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, causality_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Cross Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, enc_dec_attn = self.enc_dec_attn(out, enc_out, enc_out, padding_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, enc_dec_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: \n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: \n",
    "            out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)    \n",
    "    dec_mask = generate_causality_mask(tf.shape(tgt)[1])\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 162,
       "width": 426
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch, length = 16, 20\n",
    "src_padding = 5\n",
    "tgt_padding = 15\n",
    "\n",
    "src_pad = tf.zeros(shape=(batch, src_padding))\n",
    "tgt_pad = tf.zeros(shape=(batch, tgt_padding))\n",
    "\n",
    "sample_data = tf.ones(shape=(batch, length))\n",
    "\n",
    "sample_src = tf.concat([sample_data, src_pad], axis=-1)\n",
    "sample_tgt = tf.concat([sample_data, tgt_pad], axis=-1)\n",
    "\n",
    "enc_mask, dec_enc_mask, dec_mask = \\\n",
    "generate_masks(sample_src, sample_tgt)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "ax1.set_title('1) Encoder Mask')\n",
    "ax2.set_title('2) Encoder-Decoder Mask')\n",
    "ax3.set_title('3) Decoder Mask')\n",
    "\n",
    "ax1.imshow(enc_mask[:3, 0, 0].numpy(), cmap='Dark2')\n",
    "ax2.imshow(dec_enc_mask[0, 0].numpy(), cmap='Dark2')\n",
    "ax3.imshow(dec_mask.numpy(), cmap='Dark2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(n_layers=2, \n",
    "                          d_model=512, \n",
    "                          n_heads=8, \n",
    "                          d_ff=2048, \n",
    "                          src_vocab_size=20000,\n",
    "                          tgt_vocab_size=20000,\n",
    "                          pos_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
    "                                                            reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 함수 정의\n",
    "\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 564/564 [03:27<00:00,  2.72it/s, Loss 6.2160]\n",
      "Epoch  2: 100%|██████████| 564/564 [03:22<00:00,  2.79it/s, Loss 2.0156]\n",
      "Epoch  3: 100%|██████████| 564/564 [03:22<00:00,  2.79it/s, Loss 0.9999]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = generate_masks(_input, output)\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = model(_input, \n",
    "                                                                 output,\n",
    "                                                                 enc_padding_mask,\n",
    "                                                                 combined_mask,\n",
    "                                                                 dec_padding_mask)\n",
    "        \n",
    "\n",
    "        predicted_id = tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[0] mismatch In[1] shape: 50 vs. 1: [1,8,1,50] [1,8,1,64] 0 0 [Op:BatchMatMulV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/1734772300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mko_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_31/2261353251.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpieces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/4191350552.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence, model, src_tokenizer, tgt_tokenizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         predictions, enc_attns, dec_attns, dec_enc_attns = model(_input, \n\u001b[0m\u001b[1;32m     16\u001b[0m                                                                  \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                                  \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/143725314.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausality_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/1777448744.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_out, causality_mask, padding_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausality_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mdec_attns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/414802814.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_out, causality_mask, padding_mask)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_self_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausality_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/2215030274.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mWV_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         out, attention_weights = self.scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m     85\u001b[0m             WQ_splits, WK_splits, WV_splits, mask)\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/2215030274.py\u001b[0m in \u001b[0;36mscaled_dot_product_attention\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\" \n\u001b[1;32m     45\u001b[0m         \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_qk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3605\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[1;32m   3606\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3607\u001b[0;31m         return gen_math_ops.batch_mat_mul_v2(\n\u001b[0m\u001b[1;32m   3608\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[1;32m   3609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1507\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: In[0] mismatch In[1] shape: 50 vs. 1: [1,8,1,50] [1,8,1,64] 0 0 [Op:BatchMatMulV2]"
     ]
    }
   ],
   "source": [
    "examples = [\"오바마는 대통령이다.\",\n",
    "            \"시민들은 도시 속에 산다.\",\n",
    "            \"커피는 필요 없다.\",\n",
    "            \"일곱 명의 사망자가 발생했다.\"]\n",
    "\n",
    "for example in examples:\n",
    "    translate(example, transformer, ko_tokenizer, en_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
