{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masang/anaconda3/envs/kobert/lib/python3.9/site-packages/mxnet/numpy/utils.py:37: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  bool = onp.bool\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m below_threshold_len\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkobert\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/kobert/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2019 SK T-Brain Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkobert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m download, get_tokenizer\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkobert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_kobert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_pytorch_kobert_model\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkobert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmxnet_kobert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_mxnet_kobert_model\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkobert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx_kobert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_onnx_kobert_model\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/kobert/pytorch_kobert.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertModel\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgluonnlp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnlp\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkobert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m download, get_tokenizer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_pytorch_kobert_model\u001b[39m(ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, cachedir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.cache\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/gluonnlp/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"NLP toolkit.\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmxnet\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m loss\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/mxnet/__init__.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# version info\u001b[39;00m\n\u001b[1;32m     31\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39m__version__\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m contrib\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ndarray\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ndarray \u001b[38;5;28;01mas\u001b[39;00m nd\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/mxnet/contrib/__init__.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograd\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensorboard\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m text\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m onnx\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m io\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/mxnet/contrib/text/__init__.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vocab\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m embedding\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/mxnet/contrib/text/embedding.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_np_array\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m _mx_np\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy_extension \u001b[38;5;28;01mas\u001b[39;00m _mx_npx\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregister\u001b[39m(embedding_cls):\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/mxnet/numpy/__init__.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m random\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _op\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _register\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/mxnet/numpy/multiarray.py:47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _internal \u001b[38;5;28;01mas\u001b[39;00m _npi\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _storage_type, from_numpy\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_np_op\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import,unused-wildcard-import\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fallback\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/mxnet/numpy/utils.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m int64 \u001b[38;5;241m=\u001b[39m onp\u001b[38;5;241m.\u001b[39mint64\n\u001b[1;32m     36\u001b[0m bool_ \u001b[38;5;241m=\u001b[39m onp\u001b[38;5;241m.\u001b[39mbool_\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43monp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m\n\u001b[1;32m     39\u001b[0m pi \u001b[38;5;241m=\u001b[39m onp\u001b[38;5;241m.\u001b[39mpi\n\u001b[1;32m     40\u001b[0m inf \u001b[38;5;241m=\u001b[39m onp\u001b[38;5;241m.\u001b[39minf\n",
      "File \u001b[0;32m~/anaconda3/envs/kobert/lib/python3.9/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "from utils import below_threshold_len\n",
    "\n",
    "import kobert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 & train / val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 4828\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed amazon review dataset from directory\n",
    "train_data = pd.read_csv(\"data/preprocessed_combined_train.csv\")\n",
    "print('전체 샘플수 :', (len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 9\n",
      "텍스트의 최대 길이 : 239\n",
      "텍스트의 평균 길이 : 53.5735294117647\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_len = [len(s.split()) for s in train_data['conversation']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "# mean + 2*std를 텍스트 길이의 상한선으로 설정 -> 손실되는 text 5% 미만\n",
    "text_max_len = int(np.mean(text_len) + 2 * np.std(text_len))\n",
    "print(text_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 111 이하인 샘플의 비율: 0.9571251035625518\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, train_data['conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 학습 샘플수 : 4621\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data[train_data[\"conversation\"].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "\n",
    "print('전체 학습 샘플수 :', (len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    '협박 대화': 0,\n",
    "    '기타 괴롭힘 대화': 1,\n",
    "    '직장 내 괴롭힘 대화': 2,\n",
    "    '갈취 대화': 3,\n",
    "    '일반 대화': 4\n",
    "}\n",
    "\n",
    "train_data['class'] = train_data['class'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_data['conversation'])\n",
    "y_train = np.array(train_data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 3696\n",
      "훈련 레이블의 개수 : 925\n",
      "테스트 데이터의 개수 : 3696\n",
      "테스트 레이블의 개수 : 925\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 개수 :', len(x_train))\n",
    "print('훈련 레이블의 개수 :', len(x_val))\n",
    "print('테스트 데이터의 개수 :', len(y_train))\n",
    "print('테스트 레이블의 개수 :', len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텍스트 데이터 토큰화 & 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 22736\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 16132\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 6604\n",
      "단어 집합에서 희귀 단어의 비율: 70.95355383532723\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 10.631751263338279\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=6600)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "tokenizer.fit_on_texts(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[909, 2677, 16, 2, 23, 25, 8, 599, 149, 197, 429, 1017, 1177, 2950, 1220, 1809, 2951, 66, 161, 3, 2, 1435, 1220, 528, 481, 19, 42, 219, 909, 2677, 16, 581, 259, 67, 2952, 574, 2, 529, 19, 42, 838, 3651, 1918, 4886, 246, 283, 530, 1368], [2033, 2465, 4887, 78, 46, 78, 14, 482, 78, 127, 1919, 5, 541, 373, 2157, 2, 35, 2, 35, 4147, 2158, 6000, 2678, 113, 2465, 4888, 1436, 4, 26, 48, 839, 10, 46, 482, 40, 1920, 10, 78, 26, 2, 35, 48, 88, 1810, 47, 3, 158, 60, 289, 113, 196, 6, 2953, 33, 52, 267, 6001, 44, 5, 6, 300, 1104, 6, 2954, 1, 430, 2466, 82, 840, 1105, 52, 4148, 78, 14, 2034], [2035, 72, 27, 397, 1018, 28, 142, 8, 139, 1437, 72, 225, 500, 1723, 2, 6002, 11, 1141, 27, 208, 2, 938]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "x_train_tk = tokenizer.texts_to_sequences(x_train)\n",
    "x_val_tk = tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(x_train_tk[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tk = tf.keras.utils.pad_sequences(x_train_tk, maxlen=text_max_len, padding='post')\n",
    "x_val_tk = tf.keras.utils.pad_sequences(x_val_tk, maxlen=text_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 초기화 & 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masang/anaconda3/envs/tfenv/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739943679.756067   62832 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739943679.787651   62832 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739943679.789380   62832 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739943679.792306   62832 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739943679.793996   62832 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739943679.795555   62832 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739943679.895642   62832 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739943679.896912   62832 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739943679.898091   62832 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-19 14:41:19.899269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,689,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,689,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,862,533</span> (7.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,862,533\u001b[0m (7.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,862,533</span> (7.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,862,533\u001b[0m (7.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_size = 6600    # 어휘 사전의 크기입니다(3~9999의 인덱스 범위)\n",
    "embed_dim = 256  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# lstm model\n",
    "lstm = tf.keras.Sequential()\n",
    "lstm.add(tf.keras.layers.Embedding(vocab_size, embed_dim, input_shape=(None,)))\n",
    "lstm.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "lstm.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "lstm.add(tf.keras.layers.Dense(5, activation='softmax'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"models/.weights.h5\", \n",
    "                             monitor='val_accuracy', \n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max', \n",
    "                             save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 14:41:21.373348: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2190 - loss: 1.6080\n",
      "Epoch 1: val_accuracy improved from -inf to 0.39135, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.2303 - loss: 1.6066 - val_accuracy: 0.3914 - val_loss: 1.6009\n",
      "Epoch 2/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4425 - loss: 1.5948\n",
      "Epoch 2: val_accuracy improved from 0.39135 to 0.41081, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4386 - loss: 1.5937 - val_accuracy: 0.4108 - val_loss: 1.5908\n",
      "Epoch 3/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4585 - loss: 1.5794\n",
      "Epoch 3: val_accuracy improved from 0.41081 to 0.50054, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4676 - loss: 1.5783 - val_accuracy: 0.5005 - val_loss: 1.5756\n",
      "Epoch 4/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5507 - loss: 1.5601\n",
      "Epoch 4: val_accuracy improved from 0.50054 to 0.50703, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5459 - loss: 1.5578 - val_accuracy: 0.5070 - val_loss: 1.5541\n",
      "Epoch 5/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5958 - loss: 1.5316\n",
      "Epoch 5: val_accuracy improved from 0.50703 to 0.58270, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6065 - loss: 1.5286 - val_accuracy: 0.5827 - val_loss: 1.5210\n",
      "Epoch 6/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6857 - loss: 1.4872\n",
      "Epoch 6: val_accuracy improved from 0.58270 to 0.62054, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6813 - loss: 1.4810 - val_accuracy: 0.6205 - val_loss: 1.4600\n",
      "Epoch 7/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6962 - loss: 1.4108\n",
      "Epoch 7: val_accuracy did not improve from 0.62054\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6948 - loss: 1.3965 - val_accuracy: 0.5784 - val_loss: 1.3477\n",
      "Epoch 8/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6606 - loss: 1.2580\n",
      "Epoch 8: val_accuracy improved from 0.62054 to 0.64216, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6601 - loss: 1.2482 - val_accuracy: 0.6422 - val_loss: 1.2031\n",
      "Epoch 9/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6893 - loss: 1.1030\n",
      "Epoch 9: val_accuracy improved from 0.64216 to 0.64757, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6888 - loss: 1.0850 - val_accuracy: 0.6476 - val_loss: 1.0373\n",
      "Epoch 10/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6829 - loss: 0.9382\n",
      "Epoch 10: val_accuracy did not improve from 0.64757\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6788 - loss: 0.9310 - val_accuracy: 0.5600 - val_loss: 1.0328\n",
      "Epoch 11/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7086 - loss: 0.8380\n",
      "Epoch 11: val_accuracy improved from 0.64757 to 0.71568, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7222 - loss: 0.8301 - val_accuracy: 0.7157 - val_loss: 0.8705\n",
      "Epoch 12/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7801 - loss: 0.7561\n",
      "Epoch 12: val_accuracy improved from 0.71568 to 0.73946, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7795 - loss: 0.7461 - val_accuracy: 0.7395 - val_loss: 0.8092\n",
      "Epoch 13/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8019 - loss: 0.6927\n",
      "Epoch 13: val_accuracy improved from 0.73946 to 0.74919, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8055 - loss: 0.6791 - val_accuracy: 0.7492 - val_loss: 0.7560\n",
      "Epoch 14/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8383 - loss: 0.6038\n",
      "Epoch 14: val_accuracy improved from 0.74919 to 0.76000, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8385 - loss: 0.6020 - val_accuracy: 0.7600 - val_loss: 0.7204\n",
      "Epoch 15/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8523 - loss: 0.5554\n",
      "Epoch 15: val_accuracy did not improve from 0.76000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8594 - loss: 0.5497 - val_accuracy: 0.7503 - val_loss: 0.7062\n",
      "Epoch 16/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8797 - loss: 0.4958\n",
      "Epoch 16: val_accuracy did not improve from 0.76000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8814 - loss: 0.4954 - val_accuracy: 0.7557 - val_loss: 0.6869\n",
      "Epoch 17/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8956 - loss: 0.4744\n",
      "Epoch 17: val_accuracy improved from 0.76000 to 0.78486, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8989 - loss: 0.4654 - val_accuracy: 0.7849 - val_loss: 0.6486\n",
      "Epoch 18/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9170 - loss: 0.4216\n",
      "Epoch 18: val_accuracy improved from 0.78486 to 0.79243, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9168 - loss: 0.4182 - val_accuracy: 0.7924 - val_loss: 0.6197\n",
      "Epoch 19/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9274 - loss: 0.3743\n",
      "Epoch 19: val_accuracy improved from 0.79243 to 0.81081, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9269 - loss: 0.3745 - val_accuracy: 0.8108 - val_loss: 0.6026\n",
      "Epoch 20/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9341 - loss: 0.3440\n",
      "Epoch 20: val_accuracy improved from 0.81081 to 0.81297, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9354 - loss: 0.3421 - val_accuracy: 0.8130 - val_loss: 0.5935\n",
      "Epoch 21/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9518 - loss: 0.3067\n",
      "Epoch 21: val_accuracy did not improve from 0.81297\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9508 - loss: 0.3049 - val_accuracy: 0.8130 - val_loss: 0.5915\n",
      "Epoch 22/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9508 - loss: 0.2833\n",
      "Epoch 22: val_accuracy improved from 0.81297 to 0.81946, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9531 - loss: 0.2790 - val_accuracy: 0.8195 - val_loss: 0.5593\n",
      "Epoch 23/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9628 - loss: 0.2509\n",
      "Epoch 23: val_accuracy did not improve from 0.81946\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9632 - loss: 0.2476 - val_accuracy: 0.8097 - val_loss: 0.5523\n",
      "Epoch 24/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9702 - loss: 0.2230\n",
      "Epoch 24: val_accuracy did not improve from 0.81946\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9698 - loss: 0.2201 - val_accuracy: 0.8119 - val_loss: 0.5834\n",
      "Epoch 25/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9729 - loss: 0.1977\n",
      "Epoch 25: val_accuracy improved from 0.81946 to 0.82486, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9730 - loss: 0.1953 - val_accuracy: 0.8249 - val_loss: 0.5237\n",
      "Epoch 26/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9756 - loss: 0.1742\n",
      "Epoch 26: val_accuracy did not improve from 0.82486\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9762 - loss: 0.1721 - val_accuracy: 0.8108 - val_loss: 0.5630\n",
      "Epoch 27/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9764 - loss: 0.1538\n",
      "Epoch 27: val_accuracy improved from 0.82486 to 0.82919, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9766 - loss: 0.1540 - val_accuracy: 0.8292 - val_loss: 0.5130\n",
      "Epoch 28/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9833 - loss: 0.1285\n",
      "Epoch 28: val_accuracy improved from 0.82919 to 0.83676, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9832 - loss: 0.1292 - val_accuracy: 0.8368 - val_loss: 0.5134\n",
      "Epoch 29/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.1138\n",
      "Epoch 29: val_accuracy did not improve from 0.83676\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9853 - loss: 0.1137 - val_accuracy: 0.8314 - val_loss: 0.5226\n",
      "Epoch 30/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9882 - loss: 0.0949\n",
      "Epoch 30: val_accuracy did not improve from 0.83676\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9876 - loss: 0.0957 - val_accuracy: 0.8335 - val_loss: 0.5167\n",
      "Epoch 31/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9906 - loss: 0.0870\n",
      "Epoch 31: val_accuracy did not improve from 0.83676\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9901 - loss: 0.0863 - val_accuracy: 0.8281 - val_loss: 0.5349\n",
      "Epoch 32/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9872 - loss: 0.0819\n",
      "Epoch 32: val_accuracy improved from 0.83676 to 0.84000, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9883 - loss: 0.0796 - val_accuracy: 0.8400 - val_loss: 0.5161\n",
      "Epoch 33/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9894 - loss: 0.0766\n",
      "Epoch 33: val_accuracy did not improve from 0.84000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9904 - loss: 0.0723 - val_accuracy: 0.8346 - val_loss: 0.5297\n",
      "Epoch 34/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0582\n",
      "Epoch 34: val_accuracy did not improve from 0.84000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9916 - loss: 0.0584 - val_accuracy: 0.8389 - val_loss: 0.5397\n",
      "Epoch 35/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9950 - loss: 0.0469\n",
      "Epoch 35: val_accuracy did not improve from 0.84000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9940 - loss: 0.0500 - val_accuracy: 0.8292 - val_loss: 0.5231\n",
      "Epoch 36/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.0623\n",
      "Epoch 36: val_accuracy did not improve from 0.84000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9904 - loss: 0.0560 - val_accuracy: 0.8314 - val_loss: 0.5318\n",
      "Epoch 37/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9942 - loss: 0.0402\n",
      "Epoch 37: val_accuracy did not improve from 0.84000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - loss: 0.0400 - val_accuracy: 0.8303 - val_loss: 0.5238\n",
      "Epoch 38/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9974 - loss: 0.0315\n",
      "Epoch 38: val_accuracy did not improve from 0.84000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9970 - loss: 0.0330 - val_accuracy: 0.8292 - val_loss: 0.5525\n",
      "Epoch 39/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0269\n",
      "Epoch 39: val_accuracy did not improve from 0.84000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9982 - loss: 0.0284 - val_accuracy: 0.8303 - val_loss: 0.5773\n",
      "Epoch 40/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9969 - loss: 0.0269\n",
      "Epoch 40: val_accuracy did not improve from 0.84000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9973 - loss: 0.0270 - val_accuracy: 0.8303 - val_loss: 0.5967\n",
      "Epoch 41/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9966 - loss: 0.0290\n",
      "Epoch 41: val_accuracy did not improve from 0.84000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9970 - loss: 0.0276 - val_accuracy: 0.8368 - val_loss: 0.6094\n",
      "Epoch 42/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0195\n",
      "Epoch 42: val_accuracy did not improve from 0.84000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9986 - loss: 0.0209 - val_accuracy: 0.8357 - val_loss: 0.5797\n",
      "Epoch 43/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0172\n",
      "Epoch 43: val_accuracy improved from 0.84000 to 0.84432, saving model to models/.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9987 - loss: 0.0186 - val_accuracy: 0.8443 - val_loss: 0.5731\n",
      "Epoch 44/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.0235\n",
      "Epoch 44: val_accuracy did not improve from 0.84432\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9978 - loss: 0.0217 - val_accuracy: 0.8389 - val_loss: 0.5886\n",
      "Epoch 45/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9969 - loss: 0.0236\n",
      "Epoch 45: val_accuracy did not improve from 0.84432\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9975 - loss: 0.0209 - val_accuracy: 0.8281 - val_loss: 0.6520\n",
      "Epoch 46/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0159\n",
      "Epoch 46: val_accuracy did not improve from 0.84432\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9986 - loss: 0.0159 - val_accuracy: 0.8400 - val_loss: 0.6138\n",
      "Epoch 47/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9996 - loss: 0.0121\n",
      "Epoch 47: val_accuracy did not improve from 0.84432\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9994 - loss: 0.0130 - val_accuracy: 0.8357 - val_loss: 0.6368\n",
      "Epoch 48/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0126\n",
      "Epoch 48: val_accuracy did not improve from 0.84432\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9990 - loss: 0.0131 - val_accuracy: 0.8400 - val_loss: 0.6494\n",
      "Epoch 49/50\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0109\n",
      "Epoch 49: val_accuracy did not improve from 0.84432\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9993 - loss: 0.0114 - val_accuracy: 0.8357 - val_loss: 0.6374\n",
      "Epoch 50/50\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0118\n",
      "Epoch 50: val_accuracy did not improve from 0.84432\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9992 - loss: 0.0117 - val_accuracy: 0.8368 - val_loss: 0.6573\n"
     ]
    }
   ],
   "source": [
    "lstm.compile(optimizer=tf.keras.optimizers.Adam(0.0002),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "history = lstm.fit(x_train_tk,\n",
    "                    y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val_tk, y_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kobert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
