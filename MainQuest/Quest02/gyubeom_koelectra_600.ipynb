{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-18T17:53:05.426822Z",
     "iopub.status.busy": "2025-02-18T17:53:05.426506Z",
     "iopub.status.idle": "2025-02-18T17:53:10.460961Z",
     "shell.execute_reply": "2025-02-18T17:53:10.459880Z",
     "shell.execute_reply.started": "2025-02-18T17:53:05.426799Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:53:10.462653Z",
     "iopub.status.busy": "2025-02-18T17:53:10.462391Z",
     "iopub.status.idle": "2025-02-18T17:53:14.541049Z",
     "shell.execute_reply": "2025-02-18T17:53:14.540016Z",
     "shell.execute_reply.started": "2025-02-18T17:53:10.462627Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0bd2a5f62c443e8da8039a55dfa3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfee50f81b7c47a2aafaf2517608ac8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/263k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c559c8c4fdde45b199cfa4b7da1711e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a72347a456142698cf8c0aff58d22cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/452M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# KoELECTRA í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë“œ\n",
    "MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"\n",
    "tokenizer = ElectraTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=4).to(device)  # 4ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:53:14.543582Z",
     "iopub.status.busy": "2025-02-18T17:53:14.543224Z",
     "iopub.status.idle": "2025-02-18T17:53:14.772200Z",
     "shell.execute_reply": "2025-02-18T17:53:14.771305Z",
     "shell.execute_reply.started": "2025-02-18T17:53:14.543540Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ë°ì´í„° ê°œìˆ˜: 4550\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import ElectraTokenizer\n",
    "\n",
    "# KoELECTRA ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"\n",
    "tokenizer = ElectraTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "train_file_path = \"/kaggle/input/aiffel-dl-thon-dktc-online-12/train.csv\"\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "more_train_file_path= \"/kaggle/input/unmlve/train_normal_friend_couple_family.csv\"\n",
    "more_train_df= pd.read_csv(more_train_file_path)\n",
    "train_df= pd.concat([train_df, more_train_df], ignore_index=True)\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”©\n",
    "label_encoder = LabelEncoder()\n",
    "train_df[\"label\"] = label_encoder.fit_transform(train_df[\"class\"])\n",
    "\n",
    "# KoELECTRA ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "class KoELECTRADataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",  # ğŸ”¥ ë³€ê²½: ê³ ì •ëœ íŒ¨ë”© ê¸¸ì´\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„± (max_length=256 ì ìš©)\n",
    "train_dataset = KoELECTRADataset(\n",
    "    texts=train_df[\"conversation\"].tolist(),\n",
    "    labels=train_df[\"label\"].tolist(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,  # ì ìš©ë¨\n",
    ")\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# ë°ì´í„°ì…‹ í¬ê¸° í™•ì¸\n",
    "print(f\"ì´ ë°ì´í„° ê°œìˆ˜: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:53:14.773557Z",
     "iopub.status.busy": "2025-02-18T17:53:14.773162Z",
     "iopub.status.idle": "2025-02-18T17:53:14.786240Z",
     "shell.execute_reply": "2025-02-18T17:53:14.785133Z",
     "shell.execute_reply.started": "2025-02-18T17:53:14.773527Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”      1094\n",
      "ê°ˆì·¨ ëŒ€í™”           981\n",
      "ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”     979\n",
      "í˜‘ë°• ëŒ€í™”           896\n",
      "ì¼ë°˜ ëŒ€í™”           600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pred_label ì»¬ëŸ¼ì˜ ê°’ ê°œìˆ˜ ì„¸ê¸°\n",
    "label_counts = train_df['class'].value_counts()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:53:14.787495Z",
     "iopub.status.busy": "2025-02-18T17:53:14.787232Z",
     "iopub.status.idle": "2025-02-18T18:47:43.043394Z",
     "shell.execute_reply": "2025-02-18T18:47:43.041954Z",
     "shell.execute_reply.started": "2025-02-18T17:53:14.787462Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:04<00:00,  1.16it/s, loss=0.12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.7786\n",
      "âœ… Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.042] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.2440\n",
      "âœ… Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:04<00:00,  1.16it/s, loss=0.0225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.1484\n",
      "âœ… Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.00581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0984\n",
      "âœ… Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.00903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.0705\n",
      "âœ… Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.00216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 0.0351\n",
      "âœ… Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.97]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.0177] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 0.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.00471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 0.0304\n",
      "âœ… Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.0021] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 0.0236\n",
      "âœ… Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.0029]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 0.0237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.00394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 0.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285/285 [04:05<00:00,  1.16it/s, loss=0.00295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:  28%|â–ˆâ–ˆâ–Š       | 81/285 [01:10<02:57,  1.15it/s, loss=0.0019]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-488f49a23e41>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# ì—­ì „íŒŒ & ìµœì í™”\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import ElectraForSequenceClassification, AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# KoELECTRA ëª¨ë¸ ë¡œë“œ\n",
    "model = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5).to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„\n",
    "num_epochs = 15\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ë°°ì¹˜ ë°ì´í„° GPUë¡œ ì´ë™\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # ëª¨ë¸ ì¶œë ¥\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # ì—­ì „íŒŒ & ìµœì í™”\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_description(f\"Epoch {epoch+1}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ëª¨ë¸ ì €ì¥ (ìµœì  ëª¨ë¸)\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), \"/kaggle/working/best_model.pt\")\n",
    "        print(\"âœ… Model Saved!\")\n",
    "\n",
    "print(\"ğŸ‰ Training Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T19:02:54.084664Z",
     "iopub.status.busy": "2025-02-18T19:02:54.084361Z",
     "iopub.status.idle": "2025-02-18T19:03:04.514609Z",
     "shell.execute_reply": "2025-02-18T19:03:04.513307Z",
     "shell.execute_reply.started": "2025-02-18T19:02:54.084641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "<ipython-input-39-1fc9ec158376>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ElectraForSequenceClassification\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "test_file_path = \"/kaggle/input/aiffel-dl-thon-dktc-online-12/test.csv\"\n",
    "submission_file_path = \"/kaggle/working/submission.csv\"\n",
    "model_path = \"/kaggle/working/best_model.pt\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "class TestKoELECTRADataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "# ğŸ”¥ test_df[\"conversation\"] â†’ test_df[\"text\"]ë¡œ ìˆ˜ì •\n",
    "test_dataset = TestKoELECTRADataset(\n",
    "    texts=test_df[\"text\"].tolist(),  # âœ… ì—¬ê¸° ìˆ˜ì •ë¨!\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ìˆ«ìë¥¼ ì›ë˜ ë¼ë²¨(`class`)ë¡œ ë³€í™˜\n",
    "test_df[\"class\"] = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "test_df[[\"idx\", \"class\"]].to_csv(submission_file_path, index=False)\n",
    "print(f\"âœ… ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {submission_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T19:07:22.858579Z",
     "iopub.status.busy": "2025-02-18T19:07:22.858221Z",
     "iopub.status.idle": "2025-02-18T19:07:33.393195Z",
     "shell.execute_reply": "2025-02-18T19:07:33.391910Z",
     "shell.execute_reply.started": "2025-02-18T19:07:22.858551Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "<ipython-input-53-03f7461e7508>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¼ë°˜ ëŒ€í™” ê°•í™” í›„ ì„œë¸Œë¯¸ì…˜ ì €ì¥ ì™„ë£Œ! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ê¸°ì¡´ ì„œë¸Œë¯¸ì…˜ íŒŒì¼ ë¡œë“œ\n",
    "submission_path = \"/kaggle/working/submission.csv\"\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model_path = \"/kaggle/working/best_model.pt\"\n",
    "model = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "test_file_path = \"/kaggle/input/aiffel-dl-thon-dktc-online-12/test.csv\"\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "class TestKoELECTRADataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "test_dataset = TestKoELECTRADataset(\n",
    "    texts=test_df[\"text\"].tolist(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "predictions = []\n",
    "probabilities = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        probs = F.softmax(outputs.logits, dim=1)  # í™•ë¥  ë³€í™˜\n",
    "\n",
    "        max_probs, preds = torch.max(probs, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        probabilities.extend(max_probs.cpu().numpy())\n",
    "\n",
    "# í´ë˜ìŠ¤ ë§¤í•‘\n",
    "class_mapping = {\n",
    "    0: \"ê°ˆì·¨ ëŒ€í™”\",\n",
    "    1: \"ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”\",\n",
    "    2: \"ì¼ë°˜ ëŒ€í™”\",\n",
    "    3: \"ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”\",\n",
    "    4: \"í˜‘ë°• ëŒ€í™”\",\n",
    "}\n",
    "\n",
    "# Softmax í™•ë¥ ì´ 0.3 ì´í•˜ì¸ ê²½ìš° ì¼ë°˜ ëŒ€í™”ë¡œ ìë™ ë³´ì •\n",
    "for i in range(len(probabilities)):\n",
    "    if probabilities[i] < 0.9:\n",
    "        predictions[i] = 2  # ì¼ë°˜ ëŒ€í™”\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ì €ì¥\n",
    "test_df[\"class\"] = [class_mapping[p] for p in predictions]\n",
    "test_df[[\"idx\", \"class\"]].to_csv(\"/kaggle/working/submission_adjusted.csv\", index=False)\n",
    "\n",
    "print(\"âœ… ì¼ë°˜ ëŒ€í™” ê°•í™” í›„ ì„œë¸Œë¯¸ì…˜ ì €ì¥ ì™„ë£Œ! ğŸš€\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softmax ê¸°ë°˜ ì²˜ë¦¬ ì „ submission ê²°ê³¼: 0.68678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T19:03:38.141501Z",
     "iopub.status.busy": "2025-02-18T19:03:38.141148Z",
     "iopub.status.idle": "2025-02-18T19:03:38.148384Z",
     "shell.execute_reply": "2025-02-18T19:03:38.147246Z",
     "shell.execute_reply.started": "2025-02-18T19:03:38.141469Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "ê°ˆì·¨ ëŒ€í™”          156\n",
      "ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”      134\n",
      "í˜‘ë°• ëŒ€í™”          105\n",
      "ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”     99\n",
      "ì¼ë°˜ ëŒ€í™”            6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#softmax ê¸°ë°˜ í•„í„°ë§ ë¯¸ì ìš©\n",
    "# pred_label ì»¬ëŸ¼ì˜ ê°’ ê°œìˆ˜ ì„¸ê¸°\n",
    "label_counts = test_df['class'].value_counts()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softmax ì²˜ë¦¬ í›„ submission ê²°ê³¼: 0.69439  \n",
    "# í›„ì²˜ë¦¬ ê¸°ë²• ë³„ ì˜í–¥ ì—†ëŠ”ë“¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T19:07:33.395586Z",
     "iopub.status.busy": "2025-02-18T19:07:33.395187Z",
     "iopub.status.idle": "2025-02-18T19:07:33.402791Z",
     "shell.execute_reply": "2025-02-18T19:07:33.401936Z",
     "shell.execute_reply.started": "2025-02-18T19:07:33.395551Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "ê°ˆì·¨ ëŒ€í™”          146\n",
      "ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”      119\n",
      "í˜‘ë°• ëŒ€í™”           97\n",
      "ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”     92\n",
      "ì¼ë°˜ ëŒ€í™”           46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#softmax ê¸°ë°˜ í•„í„°ë§ ì ìš©\n",
    "# pred_label ì»¬ëŸ¼ì˜ ê°’ ê°œìˆ˜ ì„¸ê¸°\n",
    "label_counts = test_df['class'].value_counts()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T19:07:57.385891Z",
     "iopub.status.busy": "2025-02-18T19:07:57.385495Z",
     "iopub.status.idle": "2025-02-18T19:07:57.398486Z",
     "shell.execute_reply": "2025-02-18T19:07:57.397408Z",
     "shell.execute_reply.started": "2025-02-18T19:07:57.385832Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„œë¸Œë¯¸ì…˜ íŒŒì¼ ë³€í™˜ ì™„ë£Œ! ì €ì¥ ê²½ë¡œ: submission_final.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "submission_df = test_df\n",
    "\n",
    "# í´ë˜ìŠ¤ ë§¤í•‘ ì •ì˜\n",
    "class_mapping = {\n",
    "    \"í˜‘ë°• ëŒ€í™”\": \"00\",\n",
    "    \"ê°ˆì·¨ ëŒ€í™”\": \"01\",\n",
    "    \"ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”\": \"02\",\n",
    "    \"ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”\": \"03\",\n",
    "    \"ì¼ë°˜ ëŒ€í™”\": \"04\",\n",
    "}\n",
    "\n",
    "# í´ë˜ìŠ¤ëª… â†’ ìˆ«ìë¡œ ë³€í™˜\n",
    "submission_df[\"class_no\"] = submission_df[\"class\"].map(class_mapping)\n",
    "submission_df.drop(columns=[\"class\"], inplace=True)\n",
    "# ì»¬ëŸ¼ëª… ë³€í™˜\n",
    "submission_df = submission_df.rename(columns={\"class_no\": \"class\"})\n",
    "\n",
    "# ìµœì¢… í˜•ì‹ ë§ì¶”ê¸°\n",
    "submission_df = submission_df[[\"idx\", \"class\"]]\n",
    "\n",
    "# ìƒˆë¡œìš´ ì„œë¸Œë¯¸ì…˜ íŒŒì¼ ì €ì¥\n",
    "submission_final_path = \"submission_final.csv\"\n",
    "submission_df.to_csv(submission_final_path, index=False)\n",
    "\n",
    "print(f\"âœ… ì„œë¸Œë¯¸ì…˜ íŒŒì¼ ë³€í™˜ ì™„ë£Œ! ì €ì¥ ê²½ë¡œ: {submission_final_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T07:42:18.512127Z",
     "iopub.status.busy": "2025-02-18T07:42:18.511838Z",
     "iopub.status.idle": "2025-02-18T07:42:22.820890Z",
     "shell.execute_reply": "2025-02-18T07:42:22.819971Z",
     "shell.execute_reply.started": "2025-02-18T07:42:18.512106Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ! ì¼ë°˜ ëŒ€í™” í•„í„°ë§ ì ìš©ë¨. ê²°ê³¼ ì €ì¥: /kaggle/working/submission_5.csv\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "submission_file_path_5 = \"/kaggle/working/submission_5.csv\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "class TestKoELECTRADataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° DataLoader ìƒì„±\n",
    "test_dataset = TestKoELECTRADataset(\n",
    "    texts=test_df[\"text\"].tolist(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=256,\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=1)  # í™•ë¥  ë³€í™˜\n",
    "\n",
    "        max_probs, preds = torch.max(probs, dim=1)\n",
    "        predictions.extend(zip(preds.cpu().numpy(), max_probs.cpu().numpy()))\n",
    "\n",
    "# ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ìˆ«ìë¥¼ ì›ë˜ ë¼ë²¨(`class`)ë¡œ ë³€í™˜\n",
    "pred_labels = [label_encoder.inverse_transform([p[0]])[0] for p in predictions]\n",
    "pred_probs = [p[1] for p in predictions]\n",
    "\n",
    "# ì¼ë°˜ ëŒ€í™” í•„í„°ë§ ê¸°ì¤€: í™•ë¥ ì´ ì¼ì • ì„ê³„ê°’ ì´í•˜ì¼ ê²½ìš°\n",
    "threshold = 0.8  # í™•ì‹ ì´ ë‚®ì€ ìƒ˜í”Œì„ ì¼ë°˜ ëŒ€í™”ë¡œ ê°„ì£¼\n",
    "for i in range(len(pred_probs)):\n",
    "    if pred_probs[i] < threshold:\n",
    "        pred_labels[i] = \"ì¼ë°˜ ëŒ€í™”\"\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "test_df[\"class\"] = pred_labels\n",
    "test_df[[\"idx\", \"class\"]].to_csv(submission_file_path_5, index=False)\n",
    "print(f\"âœ… ì˜ˆì¸¡ ì™„ë£Œ! ì¼ë°˜ ëŒ€í™” í•„í„°ë§ ì ìš©ë¨. ê²°ê³¼ ì €ì¥: {submission_file_path_5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T11:01:28.297616Z",
     "iopub.status.busy": "2025-02-18T11:01:28.297336Z",
     "iopub.status.idle": "2025-02-18T11:02:03.186824Z",
     "shell.execute_reply": "2025-02-18T11:02:03.185792Z",
     "shell.execute_reply.started": "2025-02-18T11:01:28.297593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ì—ì„œ ê° í´ë˜ìŠ¤ì˜ í‰ê·  ë²¡í„°(Î¼)ì™€ ê³µë¶„ì‚° í–‰ë ¬(Î£) êµ¬í•˜ê¸°\n",
    "class_means = {}  # ê° í´ë˜ìŠ¤ë³„ í‰ê·  ë²¡í„°\n",
    "class_cov_inv = {}  # ê° í´ë˜ìŠ¤ë³„ ê³µë¶„ì‚° í–‰ë ¬ì˜ ì—­í–‰ë ¬\n",
    "\n",
    "features = {label: [] for label in label_encoder.classes_}  # í´ë˜ìŠ¤ë³„ íŠ¹ì§• ë²¡í„° ì €ì¥\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "\n",
    "        # ëª¨ë¸ì˜ ë§ˆì§€ë§‰ íˆë“  ìŠ¤í…Œì´íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states[-1]  # ë§ˆì§€ë§‰ íˆë“  ë ˆì´ì–´\n",
    "        embeddings = hidden_states.mean(dim=1).cpu().numpy()  # í‰ê·  í’€ë§\n",
    "\n",
    "        # ê° í´ë˜ìŠ¤ë³„ íŠ¹ì§• ë²¡í„° ì €ì¥\n",
    "        for i, label in enumerate(labels):\n",
    "            features[label_encoder.inverse_transform([label])[0]].append(embeddings[i])\n",
    "\n",
    "# ê° í´ë˜ìŠ¤ë³„ í‰ê·  ë²¡í„° & ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°\n",
    "for label in features:\n",
    "    class_means[label] = np.mean(features[label], axis=0)\n",
    "    cov_matrix = np.cov(np.array(features[label]).T)\n",
    "    class_cov_inv[label] = np.linalg.pinv(cov_matrix + np.eye(cov_matrix.shape[0]) * 1e-6)  # ì•ˆì •ì  ì—­í–‰ë ¬ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T08:53:51.561055Z",
     "iopub.status.busy": "2025-02-18T08:53:51.560771Z",
     "iopub.status.idle": "2025-02-18T08:53:56.230083Z",
     "shell.execute_reply": "2025-02-18T08:53:56.229153Z",
     "shell.execute_reply.started": "2025-02-18T08:53:51.561034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mahalanobis Distance ê¸°ë°˜ ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨.\n"
     ]
    }
   ],
   "source": [
    "# Mahalanobis ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜\n",
    "def mahalanobis_distance(x, mean, cov_inv):\n",
    "    delta = x - mean\n",
    "    return np.sqrt(np.dot(np.dot(delta, cov_inv), delta.T))\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ Mahalanobis Distance ê³„ì‚°\n",
    "distances = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states[-1]  # ë§ˆì§€ë§‰ íˆë“  ë ˆì´ì–´ ë²¡í„°\n",
    "        embeddings = hidden_states.mean(dim=1).cpu().numpy()  # í‰ê·  í’€ë§\n",
    "\n",
    "        # Mahalanobis ê±°ë¦¬ ê³„ì‚°\n",
    "        batch_preds = []\n",
    "        for emb in embeddings:\n",
    "            min_dist = float(\"inf\")\n",
    "            best_class = None\n",
    "            for class_label in class_means:\n",
    "                dist = mahalanobis_distance(emb, class_means[class_label], class_cov_inv[class_label])\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    best_class = class_label\n",
    "            distances.append(min_dist)\n",
    "            batch_preds.append(best_class)\n",
    "\n",
    "        predictions.extend(batch_preds)\n",
    "\n",
    "# Mahalanobis ì„ê³„ê°’ ì„¤ì • (95% ì´ìƒ ë²—ì–´ë‚œ ë°ì´í„°ëŠ” ì¼ë°˜ ëŒ€í™”ë¡œ ë¶„ë¥˜)\n",
    "threshold = np.percentile(distances, 85)\n",
    "for i in range(len(distances)):\n",
    "    if distances[i] > threshold:\n",
    "        predictions[i] = \"ì¼ë°˜ ëŒ€í™”\"\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "test_df[\"class\"] = predictions\n",
    "test_df[[\"idx\", \"class\"]].to_csv(\"/kaggle/working/submission_mahalanobis.csv\", index=False)\n",
    "print(\"âœ… Mahalanobis Distance ê¸°ë°˜ ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T11:02:20.578355Z",
     "iopub.status.busy": "2025-02-18T11:02:20.578021Z",
     "iopub.status.idle": "2025-02-18T11:04:41.299613Z",
     "shell.execute_reply": "2025-02-18T11:04:41.298323Z",
     "shell.execute_reply.started": "2025-02-18T11:02:20.578333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/mnt/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4bd3ca5c8d64>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# ê²°ê³¼ ì €ì¥\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenmax_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"idx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/data/submission_openmax.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… OpenMax ê¸°ë°˜ ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/mnt/data'"
     ]
    }
   ],
   "source": [
    "from scipy.stats import weibull_min\n",
    "\n",
    "# ê° í´ë˜ìŠ¤ë³„ ìµœê³  ì ìˆ˜ ë¶„í¬(Weibull Distribution) ê³„ì‚°\n",
    "weibull_params = {}\n",
    "\n",
    "for label in features:\n",
    "    max_logits = []\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits.cpu().numpy()\n",
    "\n",
    "            for i, label_idx in enumerate(labels):\n",
    "                if label_encoder.inverse_transform([label_idx])[0] == label:\n",
    "                    max_logits.append(np.max(logits[i]))  # ìµœê³  ì ìˆ˜ ì €ì¥\n",
    "\n",
    "    # Weibull ë¶„í¬ í”¼íŒ…\n",
    "    shape, loc, scale = weibull_min.fit(max_logits, floc=0)\n",
    "    weibull_params[label] = (shape, scale)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ OpenMax ì ìš©\n",
    "openmax_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits.cpu().numpy()\n",
    "\n",
    "        for i, logit in enumerate(logits):\n",
    "            max_score = np.max(logit)\n",
    "            best_class = label_encoder.inverse_transform([np.argmax(logit)])[0]\n",
    "\n",
    "            # Weibull ë¶„í¬ì—ì„œ ë²—ì–´ë‚˜ë©´ ì¼ë°˜ ëŒ€í™”ë¡œ ë¶„ë¥˜\n",
    "            shape, scale = weibull_params[best_class]\n",
    "            weibull_cdf = weibull_min.cdf(max_score, shape, scale=scale)\n",
    "\n",
    "            if weibull_cdf < 0.05:  # 5% í™•ë¥  ì´í•˜ì¸ ë°ì´í„°ëŠ” ì¼ë°˜ ëŒ€í™”ë¡œ ì„¤ì •\n",
    "                openmax_preds.append(\"ì¼ë°˜ ëŒ€í™”\")\n",
    "            else:\n",
    "                openmax_preds.append(best_class)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "test_df[\"class\"] = openmax_preds\n",
    "test_df[[\"idx\", \"class\"]].to_csv(\"/kaggle/working/submission_openmax.csv\", index=False)\n",
    "print(\"âœ… OpenMax ê¸°ë°˜ ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T16:23:15.096380Z",
     "iopub.status.busy": "2025-02-18T16:23:15.095937Z",
     "iopub.status.idle": "2025-02-18T16:23:15.106377Z",
     "shell.execute_reply": "2025-02-18T16:23:15.105454Z",
     "shell.execute_reply.started": "2025-02-18T16:23:15.096341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "ê°ˆì·¨ ëŒ€í™”          132\n",
      "í˜‘ë°• ëŒ€í™”          126\n",
      "ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”      125\n",
      "ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”    113\n",
      "ì¼ë°˜ ëŒ€í™”            4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pred_label ì»¬ëŸ¼ì˜ ê°’ ê°œìˆ˜ ì„¸ê¸°\n",
    "label_counts = test_df['class'].value_counts()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T11:05:31.480377Z",
     "iopub.status.busy": "2025-02-18T11:05:31.480076Z",
     "iopub.status.idle": "2025-02-18T11:05:31.487580Z",
     "shell.execute_reply": "2025-02-18T11:05:31.486759Z",
     "shell.execute_reply.started": "2025-02-18T11:05:31.480355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenMax ê¸°ë°˜ ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨.\n"
     ]
    }
   ],
   "source": [
    "test_df[[\"idx\", \"class\"]].to_csv(\"/kaggle/working/submission_openmax.csv\", index=False)\n",
    "print(\"âœ… OpenMax ê¸°ë°˜ ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11088421,
     "sourceId": 93120,
     "sourceType": "competition"
    },
    {
     "datasetId": 6692897,
     "sourceId": 10785666,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
